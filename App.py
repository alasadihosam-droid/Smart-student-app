import streamlit as st
import google.generativeai as genai
import PyPDF2
from gtts import gTTS
from PIL import Image
import io

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ---
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø´Ø§Ù…Ù„",
    page_icon="ğŸ“",
    layout="wide"
)

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­ ---
# Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø¯Ù…Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„ÙƒÙˆØ¯ ÙƒÙ…Ø§ Ø·Ù„Ø¨Øª
API_KEY = "AIzaSyCn33VD-Dc241aVPEkh7HuSQRw0K1fHGB4"
genai.configure(api_key=API_KEY)

# --- 3. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ---

# Ø¯Ø§Ù„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ù…Ù„Ù PDF
def get_pdf_text(pdf_file):
    try:
        reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in reader.pages:
            extracted = page.extract_text()
            if extracted:
                text += extracted
        return text
    except Exception as e:
        return f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù€ PDF: {e}"

# Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª
def text_to_speech(text):
    try:
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù…Ø²Ø¹Ø¬Ø© Ù„Ù„Ù†Ø·Ù‚
        clean_text = text[:250].replace("*", "").replace("#", "").replace("-", "")
        if clean_text:
            tts = gTTS(text=clean_text, lang='ar')
            audio_bytes = io.BytesIO()
            tts.write_to_fp(audio_bytes)
            audio_bytes.seek(0)
            return audio_bytes
    except Exception as e:
        return None
    return None

# --- 4. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ---
model = genai.GenerativeModel('gemini-1.5-flash')

# --- 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ) ---
with st.sidebar:
    st.title("ğŸ“‚ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø°ÙƒÙŠ")
    st.markdown("---")
    uploaded_pdf = st.file_uploader("1ï¸âƒ£ Ø§Ø±ÙØ¹ ÙƒØªØ§Ø¨Ùƒ (PDF)", type=['pdf'])
    uploaded_image = st.file_uploader("2ï¸âƒ£ ØµÙˆØ± Ù…Ø³Ø£Ù„Ø© Ø£Ùˆ ØµÙØ­Ø©", type=['jpg', 'jpeg', 'png'])
    
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø© ---
context_text = ""
image_part = None

if uploaded_pdf:
    with st.spinner('Ø¬Ø§Ø±Ù ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒØªØ§Ø¨...'):
        context_text = get_pdf_text(uploaded_pdf)
    st.sidebar.success("âœ… Ø§Ù„ÙƒØªØ§Ø¨ Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ­Ù„ÙŠÙ„")

if uploaded_image:
    image_part = Image.open(uploaded_image)
    st.sidebar.image(image_part, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø±ÙØ¹Ù‡Ø§")

# --- 7. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.title("ğŸ“ Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ")
st.write("Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø´Ø®ØµÙŠ. ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø´Ø±Ø­ Ø§Ù„Ø¯Ø±ÙˆØ³ Ù…Ù† ÙƒØªØ¨ÙƒØŒ Ø­Ù„ Ø§Ù„Ù…Ø³Ø§Ø¦Ù„ Ù…Ù† Ø§Ù„ØµÙˆØ±ØŒ Ø£Ùˆ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù….")

# ØªÙ‡ÙŠØ¦Ø© Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Ù…Ù†Ø·Ù‚Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„
if prompt := st.chat_input("Ø¨Ù…Ø§Ø°Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"):
    
    # Ø¥Ø¶Ø§ÙØ© Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ø³Ø¬Ù„ ÙˆØ¹Ø±Ø¶Ù‡
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ
    with st.chat_message("assistant"):
        with st.spinner('Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±...'):
            try:
                # Ø§Ù„Ø­Ø§Ù„Ø© 1: ÙŠÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ù…Ø¹ Ø³Ø¤Ø§Ù„
                if image_part:
                    response = model.generate_content([prompt, image_part])
                
                # Ø§Ù„Ø­Ø§Ù„Ø© 2: ÙŠÙˆØ¬Ø¯ ÙƒØªØ§Ø¨ PDF Ù…Ø¹ Ø³Ø¤Ø§Ù„
                elif context_text:
                    full_prompt = f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙƒØªØ§Ø¨: \n{context_text[:10000]}\n\nØ£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ø§Ù„ØªÙØµÙŠÙ„: {prompt}"
                    response = model.generate_content(full_prompt)
                
                # Ø§Ù„Ø­Ø§Ù„Ø© 3: Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù… Ø¨Ø¯ÙˆÙ† Ù…Ø±ÙÙ‚Ø§Øª
                else:
                    response = model.generate_content(prompt)
                
                res_text = response.text
                st.markdown(res_text)
                
                # Ø¥Ø¶Ø§ÙØ© Ø®Ø§ØµÙŠØ© Ø§Ù„ØµÙˆØª
                audio = text_to_speech(res_text)
                if audio:
                    st.audio(audio, format="audio/mp3")
                
                # Ø­ÙØ¸ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
                st.session_state.messages.append({"role": "assistant", "content": res_text})
                
            except Exception as e:
                st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {e}")

# --- Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙƒÙˆØ¯ ---
